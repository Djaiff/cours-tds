---
title: "Éléments de compréhension des statistiques"
author: "Jeffery P."
institute: "Doctorant au Laboratoire des Sciences du Numérique de Nantes (LS2N)"
date: "2019"
output: 
  beamer_presentation:
    includes:
      in_header: header.tex
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, echo=FALSE}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

## Crédits

- Ce support est inspiré du cours de M. Jean-Philippe Babin, responsable pédagogique de Licence à l'Université de Nantes -  Laboratoire de Psychologie des Pays de la Loire.

- Également, plusieurs formulations ont pu être améliorées grâce aux commentaires avisés de M. Paul Marti et M. Damien Schnebelen, tous deux doctorants au LS2N - pôle SIEL, team PACCE.


# Statistiques descriptives

## Préambule

La statistique descriptive nous permet de décrire l'ensemble des données receuillies

- Individu statistique: unité élémentaire pour laquelle on va receuillir les données
- Population: ensemble des individus statistiques
- Échantillon: sous-ensemble de la population
- Variable ou caractère: aspect auquel on s'intéresse

$\rightarrow$ l'effectif est le nombre d'individus statistiques auquels on s'intéresse, on le note en général $N$

## Variables et Catégories

Une variable peut prendre un nombre fini ou infini de valeurs que l'on nomme __modalités__

Il existe deux grands types de variable:

- Les variables **qualitatives**: les modalités sont des mots/expressions
- Les variables **quantitatives**: les modalités sont des nombres entiers ou décimaux

Pour chacun de ces deux grands types, il existe deux sous-catégories...


## Les variables qualitatives

Peut-on ordonner (hiérarchiser) les modalités ?

- oui: il s'agit d'une variable **qualitative ordinale** (e.g., type de logement {appartement/maison})
- non: il s'agit d'une variable **qualitative nominale** (e.g., fréquentation {rare < occasionnelle < souvent})

## Les variables quantitatives

Peut-on énumérer les modalités sans en omettre ?

- oui: il s'agit d'une variable **quantitative discrète** (e.g., âge en année(s) $[1, 2, 3, 4, 5, \dots]$)
- non: il s'agit d'une variable **quantitative continue** (e.g., taille en cm (précision supposée infinie) [toute valeur supérieure à 0])

Remarque:

- En général l'énoncé et le contexte nous guident pour déterminer si on est dans le cas discret ou continu
- Dans les deux cas, il peut exister une infinité de valeur
- Une erreur fréquente est de considérer qu'une variable discrète a forcément des modalités entières !

## Les variables quantitatives regroupées en classe

Lorsqu'on étudie une variable quantitative disposant d'un trop grand nombre de modalités, il est souvent utile de faire un découpage en classe, i.e. on ordonne les modalités et on opère des regroupements (de même amplitude si possible)

$\rightarrow$ on appelle cela **regroupement en classe**

- Un regroupement en classe implique forcément une perte d'information
- Une variable pour laquelle on aura effectué un regroupement en classe nécessitera un traitement différent (calcul du mode, de la moyenne, de l'écart-type, etc.)

## Les variables quantitatives regroupées en classe

- Une classe est définie par sa borne inférieure ($B_{inf}$) et sa borne supérieure ($B_{sup}$)

- Les classe sont, dans la majorité des cas, des intervalles fermés à gauche et ouvert à droite i.e., une classe contient sa plus petite valeur ($B_{inf}$) mais pas sa plus grande ($B_{sup}$), on note $[B_{inf}; B_{sup}[$

Par exemple $[0; 20[$ mais pas $[0; 20]$ ou $]0; 20[$

- Pour chacune des classe de regroupement, on nomme **amplitude** la longueur de l'intervalle correspondant soit $B_{sup} -B_{inf}$. On la note souvent $a$

Par exemple un intervalle $[0; 20[$ à une amplitude de 20

- À chacune des classes, on associe un effectif souvent noté $n$ et on nomme **densité** la valeur $\frac{n}{a}$


## Première étape de description

La première fois que l'on aborde un problème il faut nécessairement trouver les réponses aux questions suivantes:

- Quelle est la population étudiée ?
- Qu'est-ce qu'un individu statistique ?
- Quel est l'échantillon ? quel est son effectif ?
- Quelles sont les variables ? pour chacune, à quelle catégorie appartient-elle et quelles sont les modalités ?

## Exemple simplifié

### Cas général

On mène une étude sur l'accès à internet en agglomération nantaise. Pour cela on enquête auprès de 1000 foyers judicieusement choisis qui ont accès à internet. Pour chacun, on demande leur débit (MB/s) ainsi que leur opérateur.

- Population: ensemble des foyers en agglomération nantaise qui ont accès à internet
- Individu statistiques: un foyer nantais ayant accès à internet
- Échantillon: 1000 foyers nantais ayant accès à internet
- Variables:

- Débits: variable quantitative discrète {1MB/s, 2MB/s, ....}
- Opérateur: variable qualitative nominale {orange, SFR, Free, Bouygues Télécom}

## Exemple simplifié

### Remarques

Le débit peut tout aussi bien être une variable quantitative discrète regroupée en classe.

- On peut faire des classes d'amplitude égale à 20 ($a=20$): $\{[0; 20[, [20; 40[, [40; 60[, \dots\}$
- On peut faire des classes d'amplitude inégales: $\{[0; 20[, [20; 80[, [80; 150[, \dots\}$

## Deuxième étape de description

La deuxième étape de description concerne une approche par variable. Pour chacune d'elle nous allons disposer de données receuillies pour les individus statistiques de l'échantillon

Il est souvent utile d'aborder chacune des variables en déterminant si l'on dispose de données brutes ou non ?

$\rightarrow$ Pour une variable, les données sont dites **brutes** si on dispose d'une valeur pour chacun des individus statistiques, sinon on dit qu'elles sont **traitées**

Cette question n'est pas anodine, car des données déjà traitées (e.g., listées en tableau ordonné) orientent le lecteur vers des premières conclusions

## Données brutes vs. traitées (exemple)

Données brutes:

Individu     |Opérateur         | Débit
-------------|------------------|------------
Foyer 1      | Free             | 20
Foyer 2      | Orange           | 10
$\vdots$     | $\vdots$         | $\vdots$
Foyer 1000   | SFR              | 75

Données pré-traitées:

Opérateur    | Nombre de foyers | Débit moyen
-------------|------------------|------------
Free         | 95               | 20
Orange       |330               | 10
$\vdots$     | $\vdots$         | $\vdots$
B&You        | 43               | 75

## Données brutes vs. traitées (exemple)

Données pré-traitées avec regroupement en classe pour le débit...

Opérateur    | Nombre de foyers | Débit moyen
-------------|------------------|------------
Free         | 95               | [20; 40[
Orange       | 330              | [0; 20[
SFR          | 120              | [140; 160[
$\vdots$     | $\vdots$         | $\vdots$
B&You        | 43               | [60; 80[


## Présentation des données en tableau

Pour présenter une variable, nous introduisons quelques notations:

- (rappel) $N$: effectif total i.e., nombre d'individus statistiques
- $p$: nombre de modalités associés à la variable

- $n_i$: effectif d'une modalité
- $n_{ic}$: effectif cumulé i.e, somme cumulée des $n_i$
- $f_{i}$ ou $\%n_i$: pourcentage d'effectif d'une modalité ($f_i=\frac{n_i}{N}$)
- $f_{ic}$ ou $\%n_{ic}$: pourcentage cumulé ($f_i=\frac{n_{ic}}{N}$)


Quantité      |modalité 1     | modalité 2   | ... | modalité p   | Total
------------- | ------------- | ------------ | --- | ------------ |--------
$n_i$         | 2             | 13           |     |   12         | $N$     
$n_{ic}$      | 2             | 15           |     |        N     |         
$f_i$         |$\frac{2}{N}$  |$\frac{13}{N}$|     |$\frac{12}{N}$| 1 
$f_{ic}$      |$\frac{2}{N}$  |$\frac{15}{N}$|     |  1           | 1 

## Calcul du mode

Le mode est associé à une variable, il correspond à la **modalité** ayant l'effectif maximum. Il existe quelque soit la catégorie d'une variable

- Une erreur fréquente est de confondre mode et effectif associé !
- Pour une variable quantitative regroupée en classe, le mode correspond à la classe de densité maximale ($\frac{n}{a}$). Si toutes les classes sont d'amplitudes égales, le mode sera alors la classe d'effectif maximum

## Calcul du mode: exemple

Imaginons une variable avec trois modalités, et un effectif total $N=12$:

Quantité     |modalité 1     | modalité 2   | modalité 3   
------------- | ------------- | ------------ | ------------
$n_i$         | 2             | 3            |   7         

- Le mode est donc la modalité 3

## Calcul de la médiane

La médiane est la modalité qui sépare la population en deux groupes d'effectifs égaux, on la note $m_e$. En pratique:

1. On calcule le range médian i.e., le rang pour lequel on a autant d'individus au dessus qu'en dessous: $$range(m_e)=(N+1)/2$$
2. On recherche la modalité qui contient le rang médian

## Calcul de la médiane: remarques

- Le rang médian ne correspond pas tout le temps à un entier. Si l'effectif total est pair le rang médian sera toujours décimal, il correspondra à un individu fictif
- Une erreur fréquente est de confondre la médiane avec le rang médian associé !
- Il est souvent pratique d'organiser les données en tableau pour déterminer la médiane, on cherche alors le rang sur **la ligne d'effectif cumulé**


## Calcul de la médiane: exemple

Imaginons une variable avec trois modalités, et un effectif total $N=12$:

Quantité     |modalité 1     | modalité 2   | modalité 3   
------------- | ------------- | ------------ | ------------
$n_i$         | 2             | 3            |   7         
$n_{ic}$      | 2             | 5            |   12           

- Le rang médian est alors $rang(m_e) = (N+1)/2=(12+1)/2=13/2=6,5$
- La médiane est donc la modalité 3

## Calcul de la moyenne

C'est une modalité (possiblement fictive) moyenne on la note $\bar x$. Elle n'est pertinente **que pour les variables quantitatives** et se calcule différemment en fonction de 3 situations:

1. Les donnés sont brutes: $$\bar x = \frac{\sum x_i}{N}$$
2. Les données sont présentéss en tableau avec effectifs: $$\bar x = \frac{1}{N}\sum x_i\times n_i$$
3. Les données sont présentées en tableau et la variable a été regroupée en classe: $$\bar x = \frac{1}{N}\sum c_i\times n_i$$

### Notations

- $x_i$ représente une modalité
- $c_i = (B_{inf}^i + B_{sup}^i) /2$ est le centre d'une classe $i$

## Calcul de la moyenne: exemple situation 1

Imaginons un échantillon de trois individus, pour lesquels on dispose du poids (kg):

Individu     |         1     |      2       |   3
------------- | ------------- | ------------ | ------------
Modalité      | 68            | 76           |  72   


- La moyenne est alors $\bar x = \sum x_i / N = (68 + 76 + 72) / 3 = 72$


## Calcul de la moyenne: exemple situation 2

Imaginons un échantillon de 12 individus, pour lesquels on dispose du poids (kg):

Poids         |        68     |      72      |   76
------------- | ------------- | ------------ | ------------
$n_i$         | 5             | 2            |  5   


- La moyenne est alors $\bar x = \sum \frac{x_i \times n_i}{N} = (68 \times 5 + 72 \times 2 + 76 \times 5) / 12 = 72$

## Calcul de la moyenne: exemple situation 3

Imaginons un échantillon de 12 individus, pour lesquels on dispose du poids (kg):

Poids         |  [68; 72[     | [72; 76[     |   [76; 80[  
------------- | ------------- | ------------ | ------------
$c_i$         | 70            | 74           | 78   
$n_i$         | 5             | 2            |  5   


- La moyenne est alors $\bar x = \sum \frac{c_i \times n_i}{N} = (70\times 5 + 74 \times 2 + 78 \times 5) / 12 = 74$


## Le quantilage

Le quantilage est le découpage de la population en proportions égales. Il s'effectue nécessairement pour des **variables quantitatives**

Par exemple un effectif de 12 observations peut être divisé:

- En deux groupes de 6 modalités (quantiles d'ordre 6)
- En trois groupes de 4 modalités (quantiles d'ordre 4 nommés __quartiles__)
- \dots


$\rightarrow$ Les quantiles ne font pas nécessairement référence à des groupes entiers, c'est même rarement le cas.
On peut vouloir découper un effectif de 12 en 10 groupes (quantiles d'ordre 10 nommés __déciles__)


## Le quantilage

Les **quantiles** sont des modalités (possiblement non observées) qui correspondent à des séparation de l'ensemble des modalités observées.

Un quantile est toujours précisé avec deux indices:

- $p$: le nombre total de groupes
- $r$: l'index de la séparation avec $1 \leq r \leq p-1$

Si on note $Q_p^r$ le quantile $r$ d'ordre $p$ pour une variable, alors:

\textbf{Il y a une proportion au moins égale à $\frac{r}{p}$ d'observation $\leq Q_p^r$}
\textbf{Et une proportion au moins égale à $1 - \frac{r}{p}$ d'observation $\geq Q_p^r$}

## Le quantilage

### Remarques

- L'ordre $p$ d'un quantile correspond au nombre de groupes que l'on fait
- Il y a toujours $p-1$ quantiles d'ordre $p$
- Les quantiles sont ordonnés $Q_p^1 < Q_p^2 < \dots < Q_p^{p-1}$
- Bien retenir que:

- les quantiles d'ordre 4 sont appelés **quartiles** ($Q_4^.$)
- les quantiles d'ordre 10 sont nommée **déciles** ($Q_{10}^.$)
- les quantiles d'ordre 100 sont nommés **centiles** ($Q_{100}^.$)

- Le deuxième quartile correspond à la médiane ($m_e = Q_4^2$)

## Le quantilage en pratique

En pratique, on procède un peu comme pour la médiane. Il y a deux étapes:

1. On commence par déterminer le rang du quantile recherché avec la formule suivante:

$$rang(Q_p^r) = r \times \frac{N+1}{p}$$

2. On recherche la modalité associé au rang (c'est là que ça peut se corser!)


## La recherche d'une modalité associé à un rang

Cette recherche peut arriver dans deux grands cas souvent fréquents:

- On dispose des données brutes mais le rang n'est pas entier
- Les données ont été regroupées en classe

On utilise alors la méthode d'**interpolation linéaire**

## L'interpolation linéaire sur données brutes

Facile! Imaginons qu'on obtienne un rang égal à $2,7$

Supposons d'autre part que l'on dispose des 3 observations ordonnées suivantes: 4, 10, 18 \dots

- Il ne serait pas logique de privilégier la modalité 10 plutôt que 18 (et inversement)
$\rightarrow$ on imagine bien que la modalité associée au rang $2.7$ se situerait entre 10 et 18 mais plus prêt de 18 quand même...

On utilise alors le calcul d'interpolation suivant:

$$ 10 + (2,7 - 2) \times (18-10) = 15,6$$

## L'interpolation linéaire sur données brutes

Le calcul énoncé:

$$ 10 + (2,7 - 2) \times (18-10) = 15,6$$

Correspond à la formule générale:

$$ V_i + (\tilde i - i) \times (V_{i+1} - V_i)$$

où:

- $V_i$ et $V_{i+1}$: sont les valeurs des rangs entiers $i$ et $i+1$
- $\tilde i$: est le rang du quantile recherché tel que $i < \tilde i < i+1$

### Remarque:
Bien que le résultat obtenu soit plus précis avec l'interpolation sur données brutes, on ne fait pas toujours ce calcul\dots souvent, on se contente de faire la moyenne entre $V_i$ et $V_{i+1}$


## L'interpolation linéaire sur données regroupées en classe

Supposons maintenant que l'on recherche le quantile associé au rang 8 et que l'on ait les observations suivantes:

Poids         |  [68; 72[     | [72; 76[     |   [76; 80[  
------------- | ------------- | ------------ | ------------
$n_i$         | 5             | 4            |  7   
$n_{ic}$      | 5             | 9            |  16   

- On sait d'après la ligne des effectifs cumulés ($n_{ic}$) que l'individu 8 se situe dans la classe $[72; 76[$ mais où exactement ?

## L'interpolation linéaire sur données regroupées en classe

Poids         |  [68; 72[     | [72; 76[     |   [76; 80[  
------------- | ------------- | ------------ | ------------
$n_i$         | 5             | 4            |  7   
$n_{ic}$      | 5             | 9            |  12   

$\rightarrow$ L'idée est de se dire que cette classe contient 4 observations et que ces dernières sont réparties _uniformément_ de manière ordonée entre 72kg et 76kg. Cela signifie qu'ils ne sont pas tous proches de 72kg, ni tous proches de 76kg mais qu'au contraire, il y en a proches de 72kg d'autres proches de 76kg et d'autres plus proches de 74kg (centre de la classe).

En suivant cette idée l'individu 8 serait alors l'avant dernière valeur de cette classe, donc relativement proche de 76kg...


## L'interpolation linéaire sur données regroupées en classe

Poids         |  [68; 72[     | [72; 76[     |   [76; 80[  
------------- | ------------- | ------------ | ------------
$n_i$         | 5             | 4            |  7   
$n_{ic}$      | 5             | 9            |  12  
$n_{ic}'$     | 1, 2, 3, 4, 5 | 6, 7, 8, 9   |  \dots 

On utilise alors le calcul suivant:

$$ 72 + (8-5) \times \frac{(76-72)}{4} = 75kg$$

- On part de la borne inférieure ($B_{inf}^i$) de la classe, ici égale à 72
- On cherche le 8ème individu en sachant qu'il y a 5 observations $\leq B_{inf}^i$
- L'amplitude ($a_i$) de la classe  est initialement divisée en 4 ($n_i$) proportions

## L'interpolation linéaire sur données regroupées en classe


Avec les notations, le calcul:

$$ 72 + (8-5) \times \frac{(76-72)}{4}$$

Est équvalent à:

$$ B_{inf}^i + \big(\tilde i-n_{(i-1)c}\big) \times \frac{(B_{sup}^i-B_{inf}^i)}{n_i} =  B_{inf}^i + \big(\tilde i-n_{(i-1)c}\big) \times \frac{a_i}{n_i}$$
Où:

- $\tilde i$ est le rang du quantile recherché tel que $n_{(i-1)c} < \tilde i < n_{ic}$
- $n_i$ est l'effectif de la classe $i$
- $B_{inf}^i$ et $B_{sup}^i$ sont les bornes de la classe $i$ 
- $a_i$ est l'amplitude de la classe $i$ 
- $n_{(i-1)c}$ est l'effectif cumulé de la classe inférieure


## L'interpolation linéaire sur données regroupées en classe: remarques

- Le calcul précédent est intuitif (non?)
- Le calcul reste valable peu importe la nature du rang recherché, qu'il soit entier ou décimal
- L'interpolation linéaire nécessite les deux types de valeur d'effectif (non cumulé et cumulé)

### Digression

- Le calcul de la médiane est une interpolation linéaire


## Boites de dispersion

En statistique, il est souvent utile de visualiser les distributions.

On peut par exemple tracer des **boites de dispersion** (en anglais **boxplot**). Pour cela, on représente:

- Un rectangle délimité par les 1er et 3ème quartiles ($Q_1$ et $Q_3$)
- La médiane ($Q_2$) à l'intérieur de ce rectangle
- Un segment inférieur jusqu'au 1er décile ($D_1$), ou jusqu'au minimum
- Un segment supérieur jusqu'au 9ème décile ($D_9$), ou jusqu'au maximum

## Boites de dispersion

```{r, echo=FALSE}
library(ggplot2)
library(latex2exp)
ggplot(data = iris[which(iris$Species == "setosa"), ], aes(x = Species, y = Sepal.Length)) + 
  geom_dotplot(binaxis='y', stackdir='centerwhole', binwidth = .03) +
  coord_flip() +
  labs(x = "", y = "", title = "Données iris (Fisher's or Anderson's)") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())
```

## Boites de dispersion

```{r, echo=FALSE}
library(ggplot2)
library(latex2exp)
ggplot(data = iris[which(iris$Species == "setosa"), ], aes(x = Species, y = Sepal.Length)) + 
  geom_dotplot(binaxis='y', stackdir='centerwhole', binwidth = .03) +
  coord_flip() +
  labs(x = "", y = "", title = "Données iris (Fisher's or Anderson's)") +
  annotate(geom="text", x=0.95, y=4.3, label=TeX("$\\min$", output='character'), parse=TRUE) +
  annotate(geom="text", x=0.95, y=5.8, label=TeX("$\\max$", output='character'), parse=TRUE) +
  annotate(geom="text", x=0.8, y=4.8, label=TeX("$Q_1$", output='character'), parse=TRUE) +
  annotate(geom="text", x=0.8, y=5.2, label=TeX("$Q_3$", output='character'), parse=TRUE) +
  annotate(geom="text", x=0.8, y=5, label=TeX("$Q_2 = m_e$", output='character'), parse=TRUE) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())
```

## Boites de dispersion

```{r, echo=FALSE}
library(ggplot2)
library(latex2exp)
ggplot(data = iris[which(iris$Species == "setosa"), ], aes(x = Species, y = Sepal.Length)) + 
  geom_boxplot() +
  geom_dotplot(binaxis='y', stackdir='centerwhole', binwidth = .03) +
  coord_flip() +
  labs(x = "", y = "", title = "Données iris (Fisher's or Anderson's)") +
  annotate(geom="text", x=0.95, y=4.3, label=TeX("$\\min$", output='character'), parse=TRUE) +
  annotate(geom="text", x=0.95, y=5.8, label=TeX("$\\max$", output='character'), parse=TRUE) +
  annotate(geom="text", x=0.6, y=4.8, label=TeX("$Q_1$", output='character'), parse=TRUE) +
  annotate(geom="text", x=0.6, y=5.2, label=TeX("$Q_3$", output='character'), parse=TRUE) +
  annotate(geom="text", x=0.6, y=5, label=TeX("$Q_2 = m_e$", output='character'), parse=TRUE) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())
```

## Boites de dispersion: quelques intérêts

Grâce aux boites de dispersion, on peut rapidement avoir une idée de la répartition des données

- Appréhender l'échelle
- Savoir si les données sont rassemblées autour de la médiane ou dispersées\dots

De plus, les boites de dispersion permettent de comparer plusieurs distributions entre elles !

## Boites de dispersion

```{r, echo=FALSE}
library(ggplot2)
ggplot(data = iris, aes(x = Species, y = Sepal.Length, color = Species)) + 
  geom_boxplot() +
  # scale_color_manual(labels = c("mean = -1", "mean = 0", "mean = 1"), values = 1:3) +
  labs(title = "Données iris (Fisher's or Anderson's)", x = "", y = "Taille de Sépale", color = "Codes couleur") +
  annotate(geom="text", x=2.7, y=4.5, label="Outlier") +
  geom_segment(aes(x = 2.7, y = 4.6, xend = 2.9, yend = 4.8),
               arrow = arrow(length = unit(0.2, "cm"))) +
  theme(axis.text.y = element_blank(),
        axis.ticks = element_blank())
```


## Mesure de dispersion

Que pensez vous des deux courbes suivantes ?

```{r, echo=FALSE}
library(ggplot2)
set.seed((2019))
x <- seq(from = -4, to = 4, length.out = 1e3)
y1 <- dnorm(x, sd = 1)
y2 <- dnorm(x, sd = 1/2)
sample <- data.frame(x, y1, y2)
ggplot(sample, aes(x = x)) + 
  geom_line(aes(y = y1), color = 1) +
  geom_line(aes(y = y2), color = 2) +
  labs(x = "", y = "") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())
```

## Mesure de dispersion

En statistique la dispersion se nomme **variance**. Il s'agit d'une valeur strictement positive qui ne se calcule que pour des variables **quantitatives**

- La dispersion traduit le fait que les données sont plus ou moins resserrées autour de la valeur moyenne $\bar x$
- Plus la variance est élevée, plus les données seront éloignées de leur moyenne (i.e., plus l'histogramme sera aplati)
- La variance est nulle si toutes les observations ont la même valeur

## Mesure de dispersion: illustration

```{r, echo=FALSE}
library(ggplot2)
set.seed((2019))
x <- seq(from = -4, to = 4, length.out = 1e3)
y1 <- dnorm(x, sd = 1)
y2 <- dnorm(x, sd = 1/2)
y3 <- dnorm(x, sd = 1/3)
sample <- data.frame(x, y1, y2, y3)
ggplot(reshape2::melt(sample, id = "x"), aes(x = x, y=value, colour=variable)) + 
  geom_line() +
  geom_segment(aes(x = 0, y = 0, xend = 0, yend = 1.2), color = "darkblue", linetype = "dashed") +
  scale_color_manual(labels = c("sd = 1", "sd = 1/2", "sd = 1/3"), values = 1:3) +
  annotate(geom="text", x=0, y=-.02, label=TeX("moyenne", output='character'), color = "darkblue", parse=TRUE) +
  labs(x = "", y = "", title = "Lois normales", color = "Codes couleur") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())
``` 

## Mesure de dispersion: illustration

```{r, echo=FALSE}
library(ggplot2)
set.seed((2019))
x <- seq(from = 0, to = 5, length.out = 1e3)
y1 <- dexp(x, rate = 1)
y2 <- dexp(x, rate = 2)
y3 <- dexp(x, rate = 3)
sample <- data.frame(x, y1, y2, y3)
ggplot(reshape2::melt(sample, id = "x"), aes(x = x, y=value, colour=variable)) + 
  geom_line() +
  geom_segment(aes(x = 1, y = 0, xend = 1, yend = .5), color = 1, linetype = "dashed") +
  annotate(geom="text", x=1, y=-.05, label=TeX("$\\m_1 = 1$", output='character'), color = 1, parse=TRUE) +
  geom_segment(aes(x = 1/2, y = 0, xend = 1/2, yend = 1), color = 2, linetype = "dashed") +
  annotate(geom="text", x=.85, y=0.8, label=TeX("$\\m_2 = 1/2$", output='character'), color = 2, parse=TRUE) +
  geom_segment(aes(x = 1/3, y = 0, xend = 1/3, yend = 1.5), color = 3, linetype = "dashed") +
  annotate(geom="text", x=.7, y=1.5, label=TeX("$\\m_3 = 1/3$", output='character'), color = 3, parse=TRUE) +
  scale_color_manual(labels = c("sd = 1", "sd = 1/2", "sd = 1/3"), values = 1:3) +
  labs(x = "", y = "", title = "Lois exponentielles", color = "Codes couleur") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())
``` 

## Le calcul de la variance d'observation

La variance d'**observation** se note souvent $\sigma^2$ ou $\var$. Elle se calcule différemment en fonction des cas:

1. Sur données brutes:

$$ \sigma^2 = \frac{1}{N}\sum (x_i - \bar x) ^2 $$

2. Sur données traitées avec effectif:

$$ \sigma^2 = \frac{1}{N}\sum n_i(x_i - \bar x) ^2 $$

3. Sur données traitées regroupées en classes :

$$ \sigma^2 = \frac{1}{N}\sum n_i(c_i - \bar x) ^2 $$


## Éléments de compréhension de la variance

Exemple sur données brutes:

$$ \sigma^2 = \frac{1}{N}\sum (x_i - \bar x) ^2 $$

Pour obtenir la variance:

1. On calcule les écarts entre chaque observation et la valeur moyenne
2. On élève tous ces écarts au carré (puissance 2)
3. On calcule la moyenne des valeurs observées

## Éléments de compréhension de la variance

On peut montrer que:

$$ \sigma^2 = \frac{1}{N}\sum (x_i - \bar x) ^2 = \frac{1}{N}\sum x_i^2 - (\frac{1}{N}\sum x_i)^2$$

Ou encore:

$$ \sigma^2 = \bar{x^2} - {\bar x}^2, \quad \text{où $\bar{x^2} = \frac{1}{N}\sum x_i^2$}$$

Donc:

$$\sigma^2 = \text{moyenne des carrés} - \text{carré de la moyenne}$$

## Pourquoi élever au carré?

Si on n'élevait pas les écarts au carré, les valeurs pourraient se compenser. Par exemple avec les observations suivantes $2, 3, 3, 4$

- On a $\bar x := \frac{\sum x_i}{N} = \frac{2+3+3+4}{4} = 12/4 = 3$

Sans élever les écarts au carré, on trouverait:

$$\sigma^2 = \frac{1}{N}\sum (x_i - \bar x) = \frac{1}{4}\big((2-3) + (3-3) + (3-3) + (4-3)\big) = 0$$

\dots et pourtant les observations n'ont pas toutes la même valeur


## Le calcul de la variance d'échantillon

En statistique inférentielle on corrige la variance par le facteur $\frac{N}{N-1}$. On obtient ainsi une variance dite d'**échantillon**

En pratique, on applique les mêmes formules mais on divise par $N-1$ plutôt que par $N$



1. Sur données brutes:

$$ \s^2 = \frac{1}{N-1}\sum (x_i - \bar x) ^2 $$

2. Sur données traitées avec effectif:

$$ \s^2 = \frac{1}{N-1}\sum n_i(x_i - \bar x) ^2 $$

3. Sur données traitées regroupées en classes :

$$ \s^2 = \frac{1}{N-1}\sum n_i(c_i - \bar x) ^2 $$

## L'écart-type

- L'écart type est la racine carré de la variance que l'on note naturellement $\sigma$ ou $\s$ ($= \sqrt {\sigma^2}\text{ ou } \sqrt {\s^2}$)
- Puisque qu'il existe une variance d'observation et d'échantillon, on calcule également un écart-type d'observation et un écart-type d'échantillon

## Calcul de l'écart-type

1. Sur données brutes:

$$ \sigma = \sqrt{\frac{1}{N}\sum (x_i - \bar x) ^2} \quad\text{ou}\quad \s =  \sqrt{\frac{1}{N-1}\sum (x_i - \bar x) ^2} $$

2. Sur données traitées avec effectif:

$$ \sigma = \sqrt{\frac{1}{N}\sum n_i(x_i - \bar x) ^2} \quad\text{ou}\quad \s =  \sqrt{\frac{1}{N-1}\sum n_i(x_i - \bar x) ^2}  $$

3. Sur données traitées regroupées en classes :

$$ \sigma = \sqrt{\frac{1}{N}\sum n_i(c_i - \bar x) ^2} \quad\text{ou}\quad \s = \sqrt{\frac{1}{N-1}\sum n_i(c_i - \bar x) ^2} $$

## Calcul de l'écart-type: remarques

- Comme la variance, l'écart-type est strictement positif (attention aux calculs!)
- Puisqu'il se déduit de la variance (par fonction croissante), l'écart-type est aussi une mesure de dispersion qui s'interprète de la même façon
- L'écart-type est une mesure homogène aux données: si les observations sont des poids en kg, l'écart-type est aussi en kg
- Étant données plusieurs distributions, on peut comparer les dispersions avec la valeur des écart-types... mais il faut prendre quelques précautions

## Le coefficient de variation

L'écart type est sensible à l'échelle des données. On utilise alors le coefficient de variation (noté $\cv$) pour le mettre à l'échelle. Il est définit par le pourcentage suivant:

$$\cv = \frac{\s}{\bar x}\times 100$$

- Le $\cv$ est réservé aux distributions strictement positives
- Le $\cv$ est une mesure d'**homogénéité** des données, plus il est faible, plus les données sont homogènes
- En pratique si $\cv < 15\%$, on dit que les données sont homogènes
- Le $\cv$ est très utile pour comparer des distributions avec des unités différentes et/ou avec des moyennes très éloignées


# Statistiques inférentielles

## Préambule

Imaginons deux personnes qui discutent à propos d'un téléphone\dots

L'un dit: 

"J'ai dû le faire réparer deux fois en 1 an, je te déconseille d'en acheter car ils tombent rapidement en panne"

L'autre répond: 

"Ah bon ? Pourtant je connais 10 personnes qui en ont un et ils n'ont encore jamais eu de problème depuis 1 an"

$\rightarrow$ Que dire de la fiabilité du téléphone ?


## Préambule

Imaginons deux personnes qui discutent à propos d'un téléphone\dots

L'un dit: 

"J'ai dû le faire réparer deux fois en 1 an, je te déconseille d'en acheter car ils tombent rapidement en panne"

L'autre répond: 

"Ah bon ? Pourtant je connais 10 personnes qui en ont un et ils n'ont encore jamais eu de problème depuis 1 an"

$\rightarrow$ on a plutôt tendance à faire confiance à la deuxième personne non ?

## Préambule

La statistique inférentielle nous permet d'inférer sur les données i.e., de généraliser des propriétés constatées sur l'échantillon à la population entière (e.g., moyenne, dispersion ou quantiles)

Dans l'exemple précédent, si on souhaite savoir combien de temps s'écoule avant d'avoir une panne

- Comment faire sachant qu'on ne pourra étudier qu'un nombre limité d'appareils à chaque fois ?
- Est-il préférable d'avoir 10 appareils ?
- Ou 1000 appareils ?

## Quelques mots sur la loi normale

S'il y a bien une loi populaire en statistique, il s'agit de la loi normale\dots la célèbre courbe en cloche !

```{r, echo=FALSE}
library(ggplot2)
set.seed((2019))
x <- seq(from = -4, to = 4, length.out = 1e3)
y <- dnorm(x)
sample <- data.frame(x, y)
ggplot(sample, aes(x = x, y = y)) + 
  geom_line(colour = 1)+
  labs(x = "", y = "") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())

```

C'est la loi régissant toutes les distributions avec un grand nombre d'observation

## Caractéristiques de la loi normale

- La loi normale est une loi **symétrique, centrée autour de sa moyenne** 
- La symétrie de la distribution implique que **la médiane est égale à la moyenne**
- C'est une loi unimodale, **son mode est égale à la moyenne**

## Reconnaître une loi normale

En pratique, on peut supposer une distrbution normale d'après l'histogramme, ou le diagramme en barre

```{r, echo=FALSE}
library(ggplot2)
set.seed((2019))
x <- rnorm(1e3)
x_bar <- mean(x)
sample <- data.frame(obs=x)
ggplot(sample, aes(x=obs)) + 
  geom_histogram(aes(y=..density..), binwidth = .25, color = "black", fill=NA) +
  geom_density(alpha=.2) +
  geom_segment(aes(x = 0, y = 0, xend = 0, yend = .4), linetype="dashed", size = 1.2) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())+
  annotate(geom="text", x=0, y=-0.02, label=latex2exp::TeX("$\\bar{x} = m_e = mode$", output='character'), parse=TRUE) +
  labs(x = "", y = "")

```


## Quelques mots sur la loi normale

- La loi normale est définie par deux paramètres:

1. Sa moyenne souvent notée $\mu$ (où $mean$)
2. Son écart-type notée $\sigma$ (où $sd$ pour "Standard Deviation")

Sa densité de probabilité est la suivante:

$$f(x) = \frac{1}{\sqrt{2\pi \sigma^2}} \times \exp\big(-\frac{(x-\mu)^2}{2\sigma^2}\big)$$

avec une variable $X$ qui suit une loi normale de moyenne $\mu$ et d'écart-type $\sigma$

On note $X\sim \N(\mu, \sigma^2)$

## Illustration de la loi normale

Changer la moyenne d'une loi normale revient à translater la distribution vers la droite ou la gauche

```{r, echo=FALSE}
library(ggplot2)
set.seed((2019))
x <- seq(from = -4, to = 4, length.out = 1e3)
y1 <- dnorm(x, mean = -1)
y2 <- dnorm(x, mean = 0)
y3 <- dnorm(x, mean = 1)
sample <- data.frame(x, y1, y2, y3)
ggplot(reshape2::melt(sample, id = "x"), aes(x = x, y=value, colour=variable)) + 
  geom_line() +
  scale_color_manual(labels = c("mean = -1", "mean = 0", "mean = 1"), values = 1:3) +
  labs(x = "", y = "", color = "Codes couleur") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())

``` 

## Illustration de la loi normale

Changer l'écart-type d'une loi normale revient à aplatir ou resserrer sa distribution autour de sa moyenne

```{r, echo=FALSE}
library(ggplot2)
set.seed((2019))
x <- seq(from = -4, to = 4, length.out = 1e3)
y1 <- dnorm(x, sd = .5)
y2 <- dnorm(x, sd = 1)
y3 <- dnorm(x, sd = 1.5)
sample <- data.frame(x, y1, y2, y3)
ggplot(reshape2::melt(sample, id = "x"), aes(x = x, y=value, colour=variable)) + 
  geom_line() +
  scale_color_manual(labels = c("sd = .5", "sd = 1", "sd = 1.5"), values = 1:3) +
  labs(x = "", y = "", color = "Codes couleur") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())
``` 

## Propriété intéressante

Si l'on dispose d'observations d'une distribution $\N(\mu, \sigma^2)$ alors:

- 68\% des observations sont comprises dans l'intervalle $[\mu - \sigma; \mu + \sigma]$
- 95\% des observations sont comprises dans l'intervalle $[\mu - 2\sigma; \mu + 2\sigma]$
- 99,8\% des observations sont comprises dans l'intervalle $[\mu - 3\sigma; \mu + 3\sigma]$

## Estimation graphique de $\mu$ et $\sigma$

- En pratique on estime $\mu$ en prenant le centre de la distribution, et on déduit $\sigma$ en estimant l'intervalle vert

```{r, echo=FALSE}
library(ggplot2)
library(latex2exp)
set.seed((2019))
x <- rnorm(1e3)
sample <- data.frame(obs=x)
ggplot(sample, aes(x=obs)) + 
  geom_histogram(aes(y=..density..), binwidth = .25, color = "black", fill = NA) +
  geom_density(alpha=.2) +
  geom_segment(aes(x = 0, y = 0, xend = 0, yend = .4), linetype="dashed", size = 1.2) +
  geom_segment(aes(x = -1, y = 0, xend = -1, yend = .3), linetype="dashed", size = 1.2, color = "darkgreen") +
  geom_segment(aes(x = 1, y = 0, xend = 1, yend = .3), linetype="dashed", size = 1.2, color = "darkgreen") +
  annotate(geom="text", x=1, y=.32, label="68%]", color = "darkgreen") +
  annotate(geom="text", x=-1, y=.32, label="[68%", color = "darkgreen") +
  geom_segment(aes(x = -2, y = 0, xend = -2, yend = .1), linetype="dashed", size = 1.2, color = "darkblue") +
  geom_segment(aes(x = 2, y = 0, xend = 2, yend = .1), linetype="dashed", size = 1.2, color = "darkblue") +
  annotate(geom="text", x=2, y=.12, label="95%]", color = "darkblue") +
  annotate(geom="text", x=-2, y=.12, label="[95%", color = "darkblue") +
  geom_segment(aes(x = -3, y = 0, xend = -3, yend = .05), linetype="dashed", size = 1.2, color = "darkred") +
  geom_segment(aes(x = 3, y = 0, xend = 3, yend = .05), linetype="dashed", size = 1.2, color = "darkred") +
  annotate(geom="text", x=3, y=.07, label="99,8%]", color = "darkred") +
  annotate(geom="text", x=-3, y=.07, label="[99,8%", color = "darkred") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  xlab("") +
  annotate(geom="text", x=0, y=-0.02, label=TeX("$\\bar{x}$", output='character'), parse=TRUE) +
  annotate(geom='text', x=1, y=-0.02, label=TeX("$\\sigma$", output='character'), parse=TRUE) +
  annotate(geom='text', x=-1, y=-0.02, label=TeX("$-\\sigma$", output='character'), parse=TRUE) +
  annotate(geom='text', x=2, y=-0.02, label=TeX("$2\\sigma$", output='character'), parse=TRUE) +
  annotate(geom='text', x=-2, y=-0.02, label=TeX("$-2\\sigma$", output='character'), parse=TRUE) +
  annotate(geom='text', x=3, y=-0.02, label=TeX("$3\\sigma$", output='character'), parse=TRUE) +
  annotate(geom='text', x=-3, y=-0.02, label=TeX("$-3\\sigma$", output='character'), parse=TRUE)

```


## Calcul de probabilité: généralité

La probabilité pour qu'une variable aléatoire $X$ soit inférieure à une quelconque valeur $x$ s'écrit $P(X\leq x)$

- \textbf{Un probabilité est toujours positive et inférieure à 1}


### Remarque 

- Pour une variable aléatoire réelle on a: $P(-\infty < X < +\infty) = 1$
- Pour une variable continue, on a $P(X=x) = 0$, d'où:
$$P(X\leq x) = P(X < x) \text{ où encore } P(X\geq x) = P(X > x)$$

Ce résultat s'explique avec un peu de théorie mathématique que l'on ne détaillera pas ici, mais il peut être utile d'avoir ces propriétés en tête pour les exercices...

<!-- ## Calcul de probabilité: propriétés -->

<!-- Pour $a, b$ réels quelconque avec $a<b$, on a les propriétés suivantes: -->

<!-- $$ -->
<!-- \begin{array}{rcl} -->
<!-- P(X\leq b) &=& 1 - P(X>b)\\ -->
<!-- P(a\leq X \leq b) &=& P(X\leq b) - P(X\leq a)\\ -->
<!-- \end{array} -->
<!-- $$ -->

## Calcul de probabilité: lien avec l'aire sous la courbe de densité

**Cas 0**: soit $Z\sim N(0,1)$,  l'aire sous la courbe est égale à 1
$$P(-\infty < Z < +\infty) = 1$$

```{r, echo=FALSE}
require(ggplot2)
x = seq(-5, 5, length.out = 1e4)
data <- data.frame(x = x, y = dnorm(x))
ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x < 10, x, 0)), fill = "darkgrey") +
  annotate(geom="text", x=0, y=-.02, label="0") +
  annotate(geom="text", x=-3, y=.4, label=latex2exp::TeX("$P(-\\infty \\leq Z \\leq +\\infty)$", output='character'), parse=TRUE) +
  geom_segment(aes(x = -3, y = .38, xend = 0, yend = .1), arrow = arrow(length = unit(0.2, "cm"))) +
  geom_segment(aes(x = 0, y=-1e-2, xend = 0, yend = 1e-2)) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "")

```


## Calcul de probabilité: valeurs de la table

**Cas I**: soient $Z\sim N(0,1)$ et a un nombre réel **positif**
$$P(Z\leq a) \longrightarrow \text{le résultat se trouve dans la table !}$$

```{r, echo=FALSE}
require(ggplot2)
x = seq(-5, 5, length.out = 1e4)
data <- data.frame(x = x, y = dnorm(x))
ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x < 1.5, x, 0)), fill = "darkgrey") +
  annotate(geom="text", x=1.5, y=-.02, label="a") +
  geom_segment(aes(x = 1.5, y=-1e-2, xend = 1.5, yend = 1e-2)) +
  annotate(geom="text", x=-3, y=.4, label=latex2exp::TeX("$P(Z \\leq a)$", output='character'), parse=TRUE) +
  geom_segment(aes(x = -3, y = .38, xend = 0, yend = .1), arrow = arrow(length = unit(0.2, "cm"))) +
  annotate(geom="text", x=0, y=-.02, label="0") +
  geom_segment(aes(x = 0, y=-1e-2, xend = 0, yend = 1e-2)) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "")

```

## Calcul de probabilité avec la loi normale

**Cas II**: soient $Z\sim N(0,1)$ et a un nombre réel **positif**
$$P(Z\geq a) = 1 - P(Z \leq a) \longrightarrow \text{on se ramène au \textbf{cas I}}$$


```{r, echo=FALSE}
library(ggplot2)

x = seq(from = -4, to = 4, length.out = 1e3)
data <- data.frame(x = x, y = dnorm(x))
g1 <- ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x > 1.5, x, -1.5)), fill = "darkgrey") +
  annotate(geom="text", x=1.5, y=-.02, label="a") +
  geom_segment(aes(x = 1.5, y=-1e-2, xend = 1.5, yend = 1e-2)) +
  annotate(geom="text", x=0, y=-.02, label="0") +
  geom_segment(aes(x = 0, y=-1e-2, xend = 0, yend = 1e-2)) +
  annotate(geom="text", x=2.5, y=0.2, label=latex2exp::TeX("$P(Z \\geq a)$", output='character'), parse=TRUE) +
  geom_segment(aes(x = 2.5, y = .18, xend = 2.3, yend = .01), arrow = arrow(length = unit(0.2, "cm"))) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "")

g2 <- ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x < 1.5, x, 1.5)), fill = "red") +
  geom_area(mapping = aes(x = ifelse(x > 1.5, x, -1.5)), fill = "darkgrey") +
  annotate(geom="text", x=1.5, y=-.02, label="a") +
  geom_segment(aes(x = 1.5, y=-1e-2, xend = 1.5, yend = 1e-2)) +
  annotate(geom="text", x=0, y=-.02, label="0") +
  geom_segment(aes(x = 0, y=-1e-2, xend = 0, yend = 1e-2)) +
  annotate(geom="text", x=2.5, y=0.2, label=latex2exp::TeX("$1 - P(X \\leq a)$", output='character'), 
           parse=TRUE, color = "darkgrey") +
  geom_segment(aes(x = 2.5, y = 0.18, xend = 2.3, yend = .05),
               arrow = arrow(length = unit(0.2, "cm")), color = "darkgrey") +
  annotate(geom="text", x=-3, y=0.2, label=latex2exp::TeX("$P(X \\leq a)$", output='character'), 
           parse=TRUE, color = "red") +
  geom_segment(aes(x = -2.6, y = 0.18, xend = -2.1, yend = .1),
               arrow = arrow(length = unit(0.2, "cm")), color = "red") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "")

multiplot(g1, g2, cols = 2)
```

## Calcul de probabilité avec la loi normale

**Cas III**: soient $Z\sim N(0,1)$ et a un nombre réel **positif**
$$P(Z\leq -a) = P(Z \geq a) \longrightarrow \text{on se ramène au \textbf{cas II}}$$


```{r, echo=FALSE}
library(ggplot2)
x = seq(from = -4, to = 4, length.out = 1e3)
data <- data.frame(x = x, y = dnorm(x))
g1 <- ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x < -1.5, x, -1.5)), fill = "darkgrey") +
  annotate(geom="text", x=1.5, y=-.02, label="a") +
  geom_segment(aes(x = 1.5, y=-1e-2, xend = 1.5, yend = 1e-2)) +
  annotate(geom="text", x=-1.5, y=-.02, label="-a") +
  geom_segment(aes(x = -1.5, y=-1e-2, xend = -1.5, yend = 1e-2)) +
  annotate(geom="text", x=0, y=-.02, label="0") +
  geom_segment(aes(x = 0, y=-1e-2, xend = 0, yend = 1e-2)) +
  annotate(geom="text", x=-2.5, y=0.2, label=latex2exp::TeX("$P(Z \\leq -a)$", output='character'), parse=TRUE) +
  geom_segment(aes(x = -2.5, y = .18, xend = -2.3, yend = .01), arrow = arrow(length = unit(0.2, "cm"))) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "")

g2 <- ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x > 1.5, x, 1.5)), fill = "darkgrey") +
  annotate(geom="text", x=1.5, y=-.02, label="a") +
  geom_segment(aes(x = 1.5, y=-1e-2, xend = 1.5, yend = 1e-2)) +
  annotate(geom="text", x=-1.5, y=-.02, label="-a") +
  geom_segment(aes(x = -1.5, y=-1e-2, xend = -1.5, yend = 1e-2)) +
  annotate(geom="text", x=0, y=-.02, label="0") +
  geom_segment(aes(x = 0, y=-1e-2, xend = 0, yend = 1e-2)) +
  annotate(geom="text", x=2.5, y=0.2, label=latex2exp::TeX("$P(Z \\geq a)$", output='character'), parse=TRUE) +
  geom_segment(aes(x = 2.5, y = .18, xend = 2.3, yend = .01), arrow = arrow(length = unit(0.2, "cm"))) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "")

multiplot(g1, g2, cols = 2)
```

## Calcul de probabilité avec la loi normale

**Cas IV**: soient $Z\sim N(0,1)$ et a un nombre réel **positif**
$$P(Z\geq -a) = P(Z \leq a) \longrightarrow \text{on se ramène au \textbf{cas I}}$$


```{r, echo=FALSE}
library(ggplot2)
x = seq(from = -4, to = 4, length.out = 1e3)
data <- data.frame(x = x, y = dnorm(x))
g1 <- ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x > -1.5, x, -1.5)), fill = "darkgrey") +
  annotate(geom="text", x=1.5, y=-.02, label="a") +
  geom_segment(aes(x = 1.5, y=-1e-2, xend = 1.5, yend = 1e-2)) +
  annotate(geom="text", x=-1.5, y=-.02, label="-a") +
  geom_segment(aes(x = -1.5, y=-1e-2, xend = -1.5, yend = 1e-2)) +
  annotate(geom="text", x=0, y=-.02, label="0") +
  geom_segment(aes(x = 0, y=-1e-2, xend = 0, yend = 1e-2)) +
  annotate(geom="text", x=2.5, y=0.2, label=latex2exp::TeX("$P(Z \\geq -a)$", output='character'), parse=TRUE) +
  geom_segment(aes(x = 2.5, y = .18, xend = 1, yend = .1), arrow = arrow(length = unit(0.2, "cm"))) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "")

g2 <- ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x < 1.5, x, 1.5)), fill = "darkgrey") +
  annotate(geom="text", x=1.5, y=-.02, label="a") +
  geom_segment(aes(x = 1.5, y=-1e-2, xend = 1.5, yend = 1e-2)) +
  annotate(geom="text", x=-1.5, y=-.02, label="-a") +
  geom_segment(aes(x = -1.5, y=-1e-2, xend = -1.5, yend = 1e-2)) +
  annotate(geom="text", x=0, y=-.02, label="0") +
  geom_segment(aes(x = 0, y=-1e-2, xend = 0, yend = 1e-2)) +
  annotate(geom="text", x=-2.5, y=0.2, label=latex2exp::TeX("$P(Z \\leq a)$", output='character'), parse=TRUE) +
  geom_segment(aes(x = -2.5, y = .18, xend = -1, yend = .1), arrow = arrow(length = unit(0.2, "cm"))) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "")

multiplot(g1, g2, cols = 2)
```

## Résumé

![Calcul de probabilité \small \textit{(Extrait du cours de M. Gérin, Paris Ouest 2012-2013)}][normale]

## Formule de calcul avec une intervalle quelconque

Soient $Z \sim N(0,1)$ et u, v deux nombres réels avec $u\leq v$
$$P(u \leq Z\leq v) = P(Z \leq v) - P(Z \leq u)$$

## Calcul de probabilité avec la loi normale

**Cas V.1**: soient $Z \sim N(0,1)$ et $0 \leq a\leq b$
$$P(a \leq Z\leq b) = P(Z \leq b) - P(Z \leq a)$$

```{r, echo=FALSE}
require(ggplot2)
x = seq(-5, 5, length.out = 1e4)
data <- data.frame(x = x, y = dnorm(x))
ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x > 0.5 & x < 1.5, x, 0)), fill = "darkgrey") +
  annotate(geom="text", x=1.5, y=-.02, label="b") +
  geom_segment(aes(x = 1.5, y=-1e-2, xend = 1.5, yend = 1e-2)) +
  annotate(geom="text", x=.5, y=-.02, label="a") +
  geom_segment(aes(x = .5, y=-1e-2, xend = .5, yend = 1e-2)) +
  annotate(geom="text", x=0, y=-.02, label="0") +
  geom_segment(aes(x = 0, y=-1e-2, xend = 0, yend = 1e-2)) +
  annotate(geom="text", x=3, y=0.2, label=latex2exp::TeX("$P(a \\leq Z \\leq b)$", output='character'), parse=TRUE) +
  geom_segment(aes(x = 3, y = .18, xend = 1, yend = .1), arrow = arrow(length = unit(0.2, "cm"))) +
  annotate(geom="text", x=-2.5, y=0.4, label=latex2exp::TeX("\\textbf{cas I}", output='character'), parse=TRUE) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "")
```

## Calcul de probabilité avec la loi normale

**Cas V.2**: soient $Z \sim N(0,1)$ et $0 \leq a\leq b$
$$P(-a \leq Z\leq b)= P(Z \leq b) - P(Z \leq -a) = P(Z \leq b) + P(Z \leq a) - 1$$

```{r, echo=FALSE}
require(ggplot2)
x = seq(-5, 5, length.out = 1e4)
data <- data.frame(x = x, y = dnorm(x))
ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x > -1 & x < 1.5, x, 0)), fill = "darkgrey") +
  annotate(geom="text", x=1.5, y=-.02, label="b", color = "black") +
  geom_segment(aes(x = 1.5, y=-1e-2, xend = 1.5, yend = 1e-2)) +
  annotate(geom="text", x=-1, y=-.02, label="-a", color = "black") +
  geom_segment(aes(x = -1, y=-1e-2, xend = -1, yend = 1e-2)) +
  annotate(geom="text", x=0, y=-.02, label="0", color = "black") +
  geom_segment(aes(x = 0, y=-1e-2, xend = 0, yend = 1e-2)) +
  annotate(geom="text", x=2, y=0.3, label=latex2exp::TeX("$P(-a \\leq Z \\leq b)$", output='character'), parse=TRUE) +
  geom_segment(aes(x = 2, y = .28, xend = 0, yend = .1), arrow = arrow(length = unit(0.2, "cm"))) +
  annotate(geom="text", x=-2.5, y=0.4, label=latex2exp::TeX("\\textbf{cas I et III}", output='character'), parse=TRUE) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "")

```

## Calcul de probabilité avec la loi normale

**Cas V.3**: soient $Z \sim N(0,1)$ et $-a \leq -b \leq 0$
$$P(-a \leq Z\leq -b)= P(Z \leq -b) - P(Z \leq -a) = P(Z \leq a) - P(Z \leq b)$$

```{r, echo=FALSE}
require(ggplot2)
x = seq(-5, 5, length.out = 1e4)
data <- data.frame(x = x, y = dnorm(x))
ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x > -1.5 & x < -.5, x, -.5)), fill = "darkgrey") +
  annotate(geom="text", x=-.5, y=-.02, label="-b", color = "black") +
  geom_segment(aes(x = -.5, y=-1e-2, xend = -.5, yend = 1e-2)) +
  annotate(geom="text", x=-1.5, y=-.02, label="-a", color = "black") +
  geom_segment(aes(x = -1.5, y=-1e-2, xend = -1.5, yend = 1e-2)) +
  annotate(geom="text", x=0, y=-.02, label="0", color = "black") +
  geom_segment(aes(x = 0, y=-1e-2, xend = 0, yend = 1e-2)) +
  annotate(geom="text", x=-3, y=0.2, label=latex2exp::TeX("$P(-a \\leq Z \\leq -b)$", output='character'), parse=TRUE) +
  geom_segment(aes(x = -3, y = .18, xend = -1, yend = .1), arrow = arrow(length = unit(0.2, "cm"))) +
  annotate(geom="text", x=-2.5, y=0.4, label=latex2exp::TeX("\\textbf{cas III}", output='character'), parse=TRUE) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "")

```


## Transformation de la loi normale

Toute transformation _affine_ d'une loi normale est encore une loi normale i.e., quelque soit les nombre réels $a$ et $b\ne 0$ on a:

$$X\sim \N(\mu, \sigma^2) \Rightarrow aX+b\sim \N(\mu+b, a^2\times\sigma^2)$$

Par conséquent:

- si $X\sim \N(\mu, \sigma^2)$ alors $X-\mu \sim \N(0, \sigma^2)$ (**centrage**)
- si $X\sim \N(\mu, \sigma^2)$ alors $\frac{X}{\sigma} \sim \N(\mu, 1)$ (**réduction**)

En pratique, on fait souvent les deux en même temps:

- si $X\sim \N(\mu, \sigma^2)$ alors $\frac{X-\mu}{\sigma} \sim \N(0, 1)$ (**normalisation=centrage+réduction**)

## Calcul de probabilité: en pratique

Si la variable $X$ ne suite pas une loi normale centrée réduite, on peut toujours se ramener aux cas précédents, par exemple:

$$P(X \leq x) = P(\frac{X-\mu}{\sigma}\leq \frac{x-\mu}{\sigma}) = P(Z \leq \frac{x-\mu}{\sigma})$$

Où $Z\sim \N(0,1)$

$\rightarrow$ Rappel: il s'agit de la **normalisation**, cette petite transformation est très utile et beaucoup utilisée !


<!-- ## Résultats utiles pour une loi normal -->

<!-- Soit $Z\sim N(0,1)$. Pour $a, b$ réels positifs tels que $a<b$, on a: -->

<!-- 1. Relation de symétrie:  -->
<!-- $$P(Z\leq -a) = P(Z \geq a) = 1 - P(Z<a)$$ -->
<!-- 2. Cas général pour un intervalle: -->
<!-- $$\begin{array}{r c l} -->
<!--       P( -a \leq Z \leq b) &=& P(Z \leq b) - P(Z \leq -a) \\ -->
<!--                            &=& P(Z \leq b) - \big(1 - P(Z \leq a)\big) \\ -->
<!--                            &=& P(Z \leq b) + P(Z \leq a) - 1 -->
<!-- \end{array}$$ -->

<!-- 3. Conséquence pour un intervalle centré en $0$:  -->
<!-- $$P( -a \leq Z \leq a) = P(Z \leq a) - P(Z \leq -a) = 2P(Z \leq a) - 1$$ -->

## Cas pratique: calcul de probabilité

68\% des observations sont comprises dans l'intervalle $[\bar x - \sigma; \bar x + \sigma]$... Est-ce bien vrai ?

$$
\begin{array}{r c l}
P(\bar x - \sigma \leq X \leq \bar x + \sigma) &=& P(- \sigma\leq X - \bar x \leq \sigma), \quad \text{on centre}\\
&=& P(- 1\leq \frac{X - \bar x}{\sigma} \leq 1), \quad\text{on réduit}\\
&=& P(- 1\leq Z \leq 1)
\end{array}
$$

Où $Z\sim N(0, 1)$

Il faut maintenant trouver la valeur de cette probabilité sur les tables...

## Cas pratique

$$
\begin{array}{r c l}
P(\bar x - \sigma \leq X \leq \bar x + \sigma) &=& P(- 1\leq Z \leq 1)\\
&=& P(Z \leq 1) - P(Z \leq -1)\\
&=& P(Z \leq 1) - (1 - P(Z \leq 1)) \\
&=& 2P(Z \leq 1) - 1
\end{array}
$$

Où $Z\sim N(0, 1)$

### Remarque

Plus généralement, on a la formule suivante quelque soit $k$ nombre entier positif:

$$P(\bar x - k\times \sigma \leq X \leq \bar x + k\times \sigma) = P(-k\leq Z \leq k)$$

## Calcul des quantiles

Dans certains cas, on ne cherche pas à calculer une probabilité pour un $b$ donné (e.g., $P(Z\leq b)$) mais on cherche $b$ telle que la probabilité soit égale à une certaine valeur:

$$\text{On veut trouver $b$ tel que } P(X\geq b) = \alpha \text{ où } P(|X|\geq b) = \alpha$$

- Dans ce cas, on s'assure que la probabibilité concerne une variable suivant une **loi normale centrée réduite**, puis on regarde dans une des tables

## Calcul des quantiles: table 1

On recherche une une valeur $z$ telle que $P(Z>z)$ avec $Z\sim N(0,1)$:

```{r}
library(ggplot2)
x = seq(-5, 5, length.out = 1e4)
data <- data.frame(x = x, y = dnorm(x))
ggplot2::ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x > 1.5, x, 0)), fill = "darkgrey") +
  annotate(geom="text", x = 1.5, y = -.02, label = latex2exp::TeX("$z_{(1-\\alpha)}$?", output='character'), 
           parse=TRUE) +
  geom_segment(aes(x = 1.5, y = -1e-2, xend = 1.5, yend = 1e-2)) +
  annotate(geom="text", x = 0, y = -.02, label="0") +
  geom_segment(aes(x = 0, y = -1e-2, xend = 0, yend = 1e-2)) +
  annotate(geom="text", x = 3, y = .2, label = latex2exp::TeX("$\\alpha = P(Z \\geq z_{(1-\\alpha)})$", output='character'), 
           parse=TRUE) +
  geom_segment(aes(x = 3, y = .18, xend = 2, yend = .02), arrow = arrow(length = unit(0.2, "cm"))) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())

```


## Calcul des quantiles: table 2

On recherche une une valeur $z$ telle que $P(|Z|>z)$ avec $Z\sim N(0,1)$:

```{r}
library(ggplot2)
x = seq(-5, 5, length.out = 1e4)
data <- data.frame(x = x, y = dnorm(x))
ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  geom_area(mapping = aes(x = ifelse(x < -1.5, x, -1.5)), fill = "darkgrey") +
  geom_area(mapping = aes(x = ifelse(x > 1.5, x, 0)), fill = "darkgrey") +
  annotate(geom="text", x = -1.5, y = -.02, label = latex2exp::TeX("$-z_{(1-\\frac{\\alpha}{2})}$", output='character'), 
           parse=TRUE) +
  geom_segment(aes(x = -1.5, y = -1e-2, xend = -1.5, yend = 1e-2)) +
  annotate(geom="text", x = 1.5, y = -.02, label = latex2exp::TeX("$z_{(1-\\frac{\\alpha}{2})}$?", output='character'), 
           parse=TRUE) +
  geom_segment(aes(x = 1.5, y = -1e-2, xend = 1.5, yend = 1e-2)) +
  annotate(geom="text", x = 0, y = -.02, label="0") +
  geom_segment(aes(x = 0, y = -1e-2, xend = 0, yend = 1e-2)) +
  annotate(geom="text", x = -4, y = .4, label = latex2exp::TeX("$\\alpha = P(|Z| \\geq z)$", output='character'), 
           parse=TRUE) +
  annotate(geom="text", x = -3, y = .2, label = latex2exp::TeX("$\\frac{\\alpha}{2}= P(Z \\leq -z_{(1-\\frac{\\alpha}{2})})$", output='character'), 
           parse=TRUE) +
  geom_segment(aes(x = -3, y = .18, xend = -2, yend = .02), arrow = arrow(length = unit(0.2, "cm"))) +
  annotate(geom="text", x = 3, y = .2, label = latex2exp::TeX("$\\\\frac{\\alpha}{2} = P(Z \\geq z_{(1-\\frac{\\alpha}{2})})$", output='character'), 
           parse=TRUE) +
  geom_segment(aes(x = 3, y = .18, xend = 2, yend = .02), arrow = arrow(length = unit(0.2, "cm"))) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())

```


## Calcul des quantiles

Attention, cette problématique est faussement facile\dots dans la majorité des cas elle nécessite une bonne maîtrise du calcul des probabilités de la loi normale !

### Cas fréquents

- On ne demande pas de trouver $z$ tel que $P(Z\geq z)=\alpha$ mais plutôt $P(Z\leq z)=1 - \alpha$.

- On ne demande pas de trouver $z$ tel que $P(|Z|\geq z)=\alpha$ mais plutôt $P(|Z|\leq z)=1 - \alpha$.

- La probabilité porte sur une variable $X\sim N(\mu, \sigma^2)$. Il faut bien penser à centrer et réduire l'évènement (ce qui se trouve dans la probabilité) e.g., $P(X > x) = P(Z > \frac{x-\mu}{\sigma})$ où  et $Z\sim N(0, 1)$

## Calcul des quantiles

### Exemple général (théorique mais utile!)

Soit $X\sim N(\mu, \sigma)$, on suppose $\alpha\in ]0; 0.5[$ connu. 

\begin{center}\textbf{On cherche $b$ tel que $P(X>b)=\alpha$}\end{center}

Voici les étapes qui nous permettent de trouver la solution:

$$
\begin{array}{rrcl}
& P(X>b) &=& \alpha\\
\Leftrightarrow & P(Z>\frac{b-\mu}{\sigma}) &=& \alpha\\
\Leftrightarrow & P(Z \leq \frac{b-\mu}{\sigma}) &=& 1- \alpha\\
\Rightarrow & \frac{b-\mu}{\sigma} &=& z_{(1- \alpha)}\\
 & \text{Donc}\quad b &=& \mu + \sigma \times z_{(1-\alpha)}
\end{array}
$$
Avec:

- $Z\sim N(0,1)$
- $z_{(1-\alpha)}$ est le **quantile** d'ordre $(1-\alpha)$ de la loi normale centrée réduite

## Calcul des quantiles

- Rappel sur la position des déciles et quartiles extrêmes

```{r}
library(ggplot2)
x = seq(-5, 5, length.out = 1e4)
data <- data.frame(x = x, y = dnorm(x))
ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_line() +
  annotate(geom="text", x = -4, y = .4, 
           label = latex2exp::TeX("$P(Z \\geq Q_1) = 0.75$", output='character'), 
           parse=TRUE) +
  annotate(geom="text", x = -4, y = .3, 
           label = latex2exp::TeX("$P(Z \\geq Q_3) = 0.25$", output='character'), 
           parse=TRUE) +
  annotate(geom="text", x = 4, y = .4, 
           label = latex2exp::TeX("$P(Z \\geq D_1) = 0.9$", output='character'), 
           parse=TRUE) +
  annotate(geom="text", x = 4, y = .3, 
           label = latex2exp::TeX("$P(Z \\geq D_9) = 0.1$", output='character'), 
           parse=TRUE) +
  geom_segment(aes(x = -1.282, y = -1e-2, xend = -1.282, yend = 1e-2)) +
  annotate(geom="text", x = -1.282, y = -.02, 
           label = latex2exp::TeX("$D_1$", output='character'), 
           parse=TRUE) +
  geom_segment(aes(x = 1.282, y = -1e-2, xend = 1.282, yend = 1e-2)) +
  annotate(geom="text", x = 1.282, y = -.02, 
           label = latex2exp::TeX("$D_9$", output='character'), 
           parse=TRUE) +
  geom_segment(aes(x = -0.674, y = -1e-2, xend = -0.674, yend = 1e-2)) +
  annotate(geom="text", x = -0.674, y = -.02, 
           label = latex2exp::TeX("$Q_1$", output='character'), 
           parse=TRUE) +
  geom_segment(aes(x = 0.674, y = -1e-2, xend = 0.674, yend = 1e-2)) +
  annotate(geom="text", x = 0.674, y = -.02, 
           label = latex2exp::TeX("$Q_3$", output='character'), 
           parse=TRUE) +
  geom_segment(aes(x = 0, y = -1e-2, xend = 0, yend = 1e-2)) +
  annotate(geom="text", x = 0, y = -.02,
           label = latex2exp::TeX("$\\mu$", output='character'), 
           parse=TRUE) +
  ylim(-5e-2, .4) +
  labs(x = "", y = "") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())

```

## Calcul des quantiles

Soit $X\sim N(\mu, \sigma)$

### Détermination des déciles et quartiles extrêmes

En utilisant la formule précédente, il vient:

$$
\begin{array}{rrcl}
& P(X > Q_3) &=& 0.25\\
\Rightarrow & Q_3 &=& \mu + \sigma \times z_{(0.75)}
\end{array}
$$
$$
\begin{array}{rrcl}
& P(X > D_9) &=& 0.1\\
\Rightarrow & D_9 &=& \mu + \sigma \times z_{(0.9)}
\end{array}
$$


Pour rappel:

- $Q_3$: troisième quartile
- $D_9$: neuvième décile

## Calcul des quantiles

Soit $X\sim N(\mu, \sigma)$

### Détermination des déciles et quartiles extrêmes

Pour $D_1$ et $Q_1$, le calcul est un peu __sioux__. Par exemple pour $D_1$, on a:

$$
\begin{array}{rrcl}
& P(X>D_1) &=& 0.9\\
\Leftrightarrow & P(Z>\frac{D_1-\mu}{\sigma}) &=& 0.9 \quad \text{or $\frac{D_1-\mu}{\sigma} < 0$}\\
\Leftrightarrow & P(Z \leq -\frac{D_1-\mu}{\sigma}) &=& 0.9\\
\Rightarrow & -\frac{D_1-\mu}{\sigma} &=& z_{(0.9)}\\
 & \text{Donc}\quad D_1 &=& \mu - \sigma \times z_{(0.9)}
\end{array}
$$

## Calcul des quantiles

Soit $X\sim N(\mu, \sigma)$

### Détermination des déciles et quartiles extrêmes

On peut utiliser les formules suivantes pour $D_1$ et $Q_1$:

$$Q_1 = \mu - \sigma \times z_{(0.75)} = 2\times \mu - Q_3$$
$$D_1 = \mu - \sigma \times z_{(0.9)} = 2\times \mu - D_9$$


Avec:

- $Q_1$: premier quartile i.e., $P(X\geq Q_1) = 0.75$
- $Q_3$: troisième quartile i.e., $P(X \geq  Q_3) = 0.25$
- $D_1$: premier décile i.e., $P(X \geq D_1) = 0.9$ 
- $D_9$: neuvième décile i.e., $P(X \geq D_9) = 0.1$

## Intervalle de confiance: introduction

Jusqu'ici on a calculé des probabilités sur une loi normale connue.

- Imaginons maintenant que l'on dispose d'un échantillon d'obesrvations que l'on suppose issues d'une loi normale $N(\mu, \sigma^2)$

Comment faire pour estimer la vraie moyenne $\mu$ avec les données dont on dispose ?

## Intervalle de confiance: introduction

Une première intuition peut consister à supposer que la vraie moyenne $\mu$ est \og à peu près\fg{} égale à la moyenne de l'échantillon dite empirique i.e., $\bar x$

$$\text{Estimation ponctuelle : } \mu \sim \bar x$$

Néanmoins, une question que l'on peut se poser est la certitude sur cette estimation...?


## Intervalle de confiance: présentation

Un **intervalle de confiance** pour la moyenne $\mu$, de niveau $1-\alpha$ où $\alpha \in ]0;1[$, est un intervalle qui a une probabilité $1-\alpha$ de contenir la vraie valeur de $\mu$.

### Attention

- Cela ne veut pas dire que la vraie valeur $\mu$ à une probabilité $1-\alpha$ d'être dans l'intervalle. Ça n'aurait pas de sens car $\mu$ n'est pas aléatoire!

## Intervalle de confiance: cadre gaussien

Lorsqu'on dispose d'observation d'une distribution supposée gaussienne (disons $N(\mu, \sigma^2)$), on dispose de la vraie loi de la moyenne empirique:

$$\bar X_n \sim N(\mu, \frac{\sigma^2}{n})$$

Ainsi en normalisant (centrage+réduction), on peut déduire que:

$$\sqrt{n}\frac{\bar X_n -\mu}{\sigma} = \frac{\bar X_n -\mu}{\frac{\sigma}{\sqrt{n}}}  \sim N(0, 1)$$

## Intervalle de confiance: rappel sur les quantiles

En reprenant les notation des quantiles de la loi normale i.e. si $Z\sim N(0,1)$ et $\alpha \in ]0.5;1[$, $z_{1-\alpha/2}$ vérifie

$$P(Z\leq z_{(1-\alpha/2)}) = {1-\alpha/2} \quad \text{et}\quad P(Z\leq -z_{(1-\alpha/2)}) = \alpha/2$$

D'où:

$$P(-z_{(1-\alpha/2)} \leq Z\leq z_{(1-\alpha/2)}) = P(|Z|\leq z_{(1-\alpha/2)}) = 1-\alpha$$

## Intervalle de confiance: cadre gaussien

On peut écrire:

$$P(-z_{(1-\alpha/2)} \leq \sqrt{n}\frac{\bar X_n -\mu}{\sigma} \leq z_{(1-\alpha/2)}) = 1-\alpha$$

Ce qui est équvalent à écrire que:

$$P(\bar X_n - \frac{\sigma}{\sqrt n} z_{(1-\alpha/2)} \leq \mu \leq \bar X_n + \frac{\sigma}{\sqrt n} z_{(1-\alpha/2)}) = 1 - \alpha$$

## Intervalle de confiance: cadre gaussien

D'après les calculs précédents on peut écrire de manière équivalente :

$$P(\mu \in [\bar X_n - \frac{\sigma}{\sqrt n} z_{(1-\alpha/2)}; \bar X_n + \frac{\sigma}{\sqrt n} z_{(1-\alpha/2)}]) = 1-\alpha$$

Ce qui nous donne un intervalle de **probabilité** pour la moyenne Eureka !!

La formule de l'intervalle de **confiance** de **niveau $1-\alpha$** pour la moyenne est donc une réalisation de cet intervalle de probabilité compte tenu des données dont on dispose:

$$[\bar x_n - \frac{\sigma}{\sqrt n} z_{(1-\alpha/2)}; \bar x_n + \frac{\sigma}{\sqrt n} z_{(1-\alpha/2)}]$$

## Intervalle de confiance: écart-type inconnu

La formule précédente ne fonctionne que si on connaît la valeur $\sigma$... ce qui est rarement le cas !
Dans la pratique, on remplace souvent $\sigma$ par son estimation:

$$\sigma \quad\text{estimé par}\quad s=\sqrt{\frac{1}{n-1}\sum_{i=1}^n (x_i-\bar x_n)^2}$$

Cela change légèrement la loi utilisée car:

$$\sqrt{n}\frac{\bar X_n -\mu}{s} \sim \mathrm{Student}(n-1)$$

On se contente de l'admettre mais cela peut se démontrer avec un peu de théorie statistique\dots ça ne sort pas d'un chapeau !

## Intervalle de confiance: écart-type inconnu

Quand on ne connaît pas l'écart-type de la distribution étudiée, l'intervalle de **confiance** de **niveau $1-\alpha$** pour la moyenne est:

$$[\bar x_n - \frac{\sigma}{\sqrt n} t_{(1-\alpha/2)}; \bar x_n + \frac{\sigma}{\sqrt n} t_{(1-\alpha/2)}]$$

où $t_{1-\alpha/2}$ est le quantile d'ordre $1-\alpha/2$ de la loi de Student à **$n-1$** degrés de liberté

## Intervalle de confiance: écart-type inconnu

Dès que $n-1\geq 30$ on considère que la loi de Student peut être approximée par la loi normale centrée réduite donc:
$$t_{(1-\alpha/2)} \simeq z_{(1-\alpha/2)}$$
et par conséquent:

$$[\bar x_n - \frac{\sigma}{\sqrt n} t_{(1-\alpha/2)}; \bar x_n + \frac{\sigma}{\sqrt n} t_{(1-\alpha/2)}]
\simeq [\bar x_n - \frac{\sigma}{\sqrt n} z_{(1-\alpha/2)}; \bar x_n + \frac{\sigma}{\sqrt n} z_{(1-\alpha/2)}]$$

## Intervalle de confiance: cadre gaussien

### Remarque

L'intervalle de confiance $[\bar x_n - \frac{\sigma}{\sqrt n} z_{(1-\alpha/2)}; \bar x_n + \frac{\sigma}{\sqrt n} z_{(1-\alpha/2)}]$ est donc symétrique, centré sur $\bar x_n$. On écrit d'ailleur souvent par abus de notation:

$$[\bar x_n \pm \frac{\sigma}{\sqrt n} z_{(1-\alpha/2)}] \quad \text{ou}\quad [\bar x_n \pm \frac{s}{\sqrt n} t_{(1-\alpha/2)}]$$

On dit souvent que la marge d'erreur est:

$$\varepsilon = \frac{\sigma}{\sqrt n} z_{(1-\alpha/2)} \quad \text{ou}\quad \varepsilon = \frac{s}{\sqrt n} t_{(1-\alpha/2)}$$

## Intervalle de confiance: proportion

Lorsqu'on cherche à estimer une proportion $p_0$, on utilise des formules comparables. Néanmoins, on ne peut formuler un intervalle que lorsque $n$ est suffisamment grand par rapport à $p$ car on doit se contenter de la convergence vers la loi normale:

$$P \underset{n\to \infty}{\longrightarrow} N(\mu=p_0,\sigma^2=\frac{p_0(1-p_0)}{n})$$

## Intervalle de confiance: proportion

On pratique, on vérifie les conditions suivantes:

- $n\geq 3$,
- $n\times p \geq 5$
- $n\times (1-p) \geq 5$

Et on estime $\frac{p_0(1-p_0)}{n}$ par $\frac{p(1-p)}{n}$

Ainsi on en déduit l'intervalle de confiance de niveau $1-\alpha$ suivant:

$$[p - \sqrt{\frac{p(1-p)}{n}} z_{(1-\alpha/2)}; p + \sqrt{\frac{p(1-p)}{n}} z_{(1-\alpha/2)}]$$


[normale]: summary "Extrait du cours de M. Gérin (Paris Ouest)"
